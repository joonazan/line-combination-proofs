\documentclass{article}

\usepackage[numbers]{natbib}
\usepackage[a4paper]{geometry}
\usepackage[most]{tcolorbox}

\title{Towards Fast and Correct Round Elimination}
\author{Joonatan Saarhelo}

\begin{document}

\maketitle

Only sometimes incorrect proofs get published. On the other hand, most programs are wrong. The list of software that afl-fuzz\cite{AFL} found bugs in illustrates this pretty well. Despite that, software is used to prove mathematical results. In my master's thesis I want to produce a convincingly correct implementation of one such program, Round Eliminator.

\section{Round Elimination}

Brandt et al.\ introduced round elimination in 2019\ \cite{speedup}. Dennis Olivetti wrote an implementation of it called Round Eliminator\ \cite{RE}. Round Elimination has been used to prove bounds on time complexity for various problems in the LOCAL model\ \cite{tc1, tc2, tc3}.

In Round Eliminator, problems are represented as \emph{lines}. Lines are a kind of shorthand notation that compresses multiple multisets into one line. Each line is a multiset of sets and represents all the multisets obtained by choosing one color from each set.\ \cite{RE}

The new active side consists of all lines that only contain configurations present in the old passive side, excluding lines that are subsets of other lines. The new passive side consists of all configurations made of new active sides' symbols that contain a configuration from the old active side.\ \cite{DA2020}

Written as a computer program, the above definition is a very concise and slow implementation of round elimination. To prove the correctness of a round elimination algorithm it suffices to prove that its output contains exactly the configurations described in the above paragraph.

\section{Proving Correctness}

There are two parts to correctness. Correctness of the algorithm and correctness of the implementation. I will try to address both with little room for human error.

For efficiency reasons, the current Round Eliminator uses an algorithm that hasn't been analysed in any literature. My version will as well. It is important to prove that the theory behind it is sound.

An implementation may make small changes to an algorithm, like dividing a problem into chunks to reduce cache misses. Bugs may exist even in pedantic implementations due to peculiarities of programming languages, for example integer overflow.

The reasonably mature tools available for writing verified programs today are Agda, Coq, Isabelle/HOL, Lean and SAT-solvers. SAT-solvers excel in finite problems but are not directly applicable to proving theorems about objects of arbitrary size. The others should be reasonable choices for formalizing the theory. Agda does not have built-in facilities for automating proofs, it is meant to be a programming language more than a proof assistant. Lean 3 has no way of making runnable programs and Lean 4 isn't usable yet. Isabelle and Coq are suitable choices for this project.

Both Coq and Isabelle can be transpiled to OCaml and various other ML flavors.\ \cite{CoqCodegen, IsabelleCodegen} This allows writing a program and proving its correctness. But purely functional OCaml can be significantly slower than C or Rust, so ideally one should be able to prove a Rust version or make an unverified program, the output of which can be checked with a verified program.

It is easy to verify that each output line can be obtained from the input. However, it is not clear how to quickly check that no line is missing in the output. If a way to do that was found, checking the output of an unverified program would be the best option; it avoids proofs related to the specific algorithm used to produce the output, meaning it can be used to check the results of better future algorithms as well.

There are a number of fully automatic verification tools for Rust but most of them are not applicable because they only prove the absence of runtime errors. Prusti is one that allows annotating functions with their behaviour as well but based on my testing, Prusti doesn't currently support enough Rust to be used on useful programs.

Electrolysis is a project from 2016 that converts Rust to Lean 2 code, preserving behaviour but not time complexity. The code can then be proven correct in the proof assistant. It covers a remarkable amount of the Rust programming language even though it is just one person's master's thesis.\ \cite{ElectrolysisCoverage} Unfortunately this would have to be rebuilt as Electrolysis only works on 2016 Rust and Lean 2.

The seL4 microkernel has been fully verified in Isabelle by translating a subset of C99 to HOL.\ \cite{Sel4} I believe the same code could be used for verifying a Round Eliminator written in C. Unlike Rust, C is far from pure functional programming and the generated HOL involves Hoare logic, which can be painful to deal with compared to the pure functions produced by Electrolysis.

\section{Plan}

I have already started proving the theory behind round elimination in Coq. It has helped me to get a more robust understanding of it. I have also rewritten a part of round elimination so that it is several orders of magnitude faster than the old version.

If it turns out that there is no efficient way to check that an output is correct, I will write an inefficient implementation in Coq. If that succeeds, I will choose between the C to Isabelle translation and making a new version of Electrolysis. I choose to do the pure Coq version first because proving functions that you can control is strictly easier than proving generated functions.

I hope I'll come up with more algorithmic improvements while working on the proofs.

\bibliographystyle{plainnat}
\bibliography{plan}

\end{document}
